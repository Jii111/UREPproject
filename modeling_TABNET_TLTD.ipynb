{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWSBDaG1UxiN",
        "outputId": "b22f41bc-d983-4bbd-9e3e-baded50c32f5",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_tabnet\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.26.4)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.5.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (4.66.6)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.3->pytorch_tabnet) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch_tabnet) (3.0.2)\n",
            "Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytorch_tabnet\n",
            "Successfully installed pytorch_tabnet-4.1.0\n",
            "Collecting tab2img\n",
            "  Downloading tab2img-0.0.2-py3-none-any.whl.metadata (6.4 kB)\n",
            "Downloading tab2img-0.0.2-py3-none-any.whl (4.8 kB)\n",
            "Installing collected packages: tab2img\n",
            "Successfully installed tab2img-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch_tabnet\n",
        "!pip install tab2img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cznn8zfIU4q6",
        "outputId": "36c52b78-48a7-46fd-8b53-f7647e340dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mugBjAbYoidU"
      },
      "source": [
        "#### config.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdIFvW4JnV91"
      },
      "outputs": [],
      "source": [
        "# 수정\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "NUM_FOLDS_OUTTER = 2\n",
        "\n",
        "def data_loader(d0,d1):\n",
        "\n",
        "    data_names = [d0, d1]\n",
        "    data_namess = ['train','test']\n",
        "\n",
        "    data_frames = []\n",
        "    for csv_name in data_names:\n",
        "        temp_df = pd.read_csv(csv_name)\n",
        "        temp_df = temp_df.set_axis([*temp_df.columns[:-1], 'class'], axis=1)\n",
        "\n",
        "        # 문자열 데이터에 대한 fillna 적용 안함\n",
        "        for col_name in temp_df.columns:\n",
        "            if temp_df[col_name].dtype != \"object\":  # numeric type에 대해서만 fillna 적용\n",
        "                temp_df[col_name] = temp_df[col_name].fillna(temp_df[col_name].mean())\n",
        "\n",
        "        for col_name in temp_df.columns:\n",
        "            if temp_df[col_name].dtype == \"object\":\n",
        "                temp_df[col_name] = pd.Categorical(temp_df[col_name])\n",
        "                temp_df[col_name] = temp_df[col_name].cat.codes\n",
        "\n",
        "        X = temp_df.drop('class', axis=1)\n",
        "        y = temp_df['class']\n",
        "        data_frames.append((X, y, len(pd.unique(temp_df['class']))))\n",
        "\n",
        "    return data_frames, data_namess\n",
        "\n",
        "\n",
        "def indices_to_one_hot(data, nb_classes):\n",
        "    \"\"\"Convert an iterable of indices to one-hot encoded labels.\"\"\"\n",
        "    targets = np.array(data).reshape(-1)\n",
        "    return np.eye(nb_classes)[targets]\n",
        "\n",
        "\n",
        "def one_hot(y_test, n_class):\n",
        "    y_test = np.array(y_test)\n",
        "    y_test = y_test.reshape(-1, 1)\n",
        "    y_test = indices_to_one_hot(y_test, n_class)\n",
        "\n",
        "    return y_test\n",
        "\n",
        "\n",
        "class Data:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTLrd1BOo951"
      },
      "source": [
        "#### metrics.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NePRsjZo-7q"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, accuracy_score, recall_score, precision_recall_curve, auc\n",
        "from sklearn import metrics\n",
        "import math\n",
        "\n",
        "\n",
        "def eval_metrics(y_true, y_pred, y_proba, multiclass=True, n_class=4):\n",
        "\n",
        "\n",
        "    if multiclass:\n",
        "        d = {}\n",
        "        for i in range(n_class):\n",
        "            d[i] = []\n",
        "            for item in y_true:\n",
        "                if item == i:\n",
        "                    d[i].append(1)\n",
        "                else:\n",
        "                    d[i].append(0)\n",
        "\n",
        "        auc_roc = 0\n",
        "        auc_pr = 0\n",
        "        for key in d.keys():\n",
        "            try:\n",
        "                precision_auc, recall_auc, _ = precision_recall_curve(d[key], y_proba[:, key])\n",
        "            except:\n",
        "                print(y_proba[:, key])\n",
        "            if math.isnan(auc(recall_auc, precision_auc)):\n",
        "                continue\n",
        "            auc_pr = auc_pr + auc(recall_auc, precision_auc)\n",
        "\n",
        "            fpr, tpr, _ = metrics.roc_curve(d[key], y_proba[:, key])\n",
        "            if math.isnan(metrics.auc(fpr, tpr)):\n",
        "                continue\n",
        "            auc_roc = auc_roc + metrics.auc(fpr, tpr)\n",
        "\n",
        "        auc_pr = auc_pr / n_class\n",
        "        auc_roc = auc_roc / n_class\n",
        "\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "        precision = precision_score(y_true, y_pred, average='weighted')\n",
        "        recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    else:\n",
        "\n",
        "        fpr, tpr, _ = metrics.roc_curve(y_true, y_proba[:, 1])\n",
        "        precision_auc, recall_auc, _ = precision_recall_curve(y_true, y_proba[:, 1])\n",
        "\n",
        "        auc_roc = metrics.roc_auc_score(y_true, y_proba[:, 1])\n",
        "\n",
        "        auc_pr = metrics.auc(recall_auc, precision_auc)\n",
        "\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "        precision = precision_score(y_true, y_pred)\n",
        "        recall = recall_score(y_true, y_pred)\n",
        "\n",
        "    return acc, precision, recall, auc_pr, auc_roc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6W8_nDdopPs"
      },
      "source": [
        "#### main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7VRCFPNpIbd"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/Urep/TLTD-main/')\n",
        "\n",
        "import models.simple_fcnn as fcnn_lib\n",
        "import models.cnn as cnn_lib\n",
        "from models import Distiller\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.models import  Model\n",
        "\n",
        "from tab2img.converter import Tab2Img\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Reshape, GlobalAveragePooling2D, MaxPool2D, UpSampling2D,Lambda\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import applications as efn\n",
        "from tensorflow import keras\n",
        "\n",
        "def convolutional_neural_network(UP_1, UP_2, SIZE_1, SIZE_2, num_classes=2):\n",
        "    \"\"\"\n",
        "    Keras model with trander layer\n",
        "    \"\"\"\n",
        "\n",
        "    base_model = efn.DenseNet169(weights='imagenet', include_top=False, input_shape=(SIZE_1, SIZE_2, 3))\n",
        "    i = 0\n",
        "    for layer in base_model.layers:\n",
        "        if i < 100:\n",
        "            layer.trainable = False\n",
        "        else:\n",
        "            layer.trainable = True\n",
        "        i = i + 1\n",
        "         # if isinstance(layer, BatchNormalization):\n",
        "        #     layer.trainable = True\n",
        "        # else:\n",
        "        #     layer.trainable = False\n",
        "\n",
        "    model = Sequential()\n",
        "    #model.add(UpSampling2D(size=(UP_1, UP_2)))\n",
        "\n",
        "    model.add(base_model)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(2000, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txcK89oZFVst",
        "outputId": "35724ca5-bf8c-49e6-df23-52ff3f52ad9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_class :\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "# KFOLD(k=2) 반복 버전\n",
        "d0 = '/content/drive/MyDrive/Colab Notebooks/Urep/gan_data/gan6.csv'\n",
        "d1 = '/content/drive/MyDrive/Colab Notebooks/Urep/gan_data/gan_test_15k.csv'\n",
        "\n",
        "dataframes, data_namess = data_loader(d0,d1)\n",
        "\n",
        "train_df = dataframes[0]\n",
        "test_df = dataframes[1]\n",
        "\n",
        "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
        "max_features = ['sqrt', 'log2', None]\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
        "max_depth.append(None)\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "bootstrap = [True, False]\n",
        "random_grid = {'n_estimators': n_estimators,'max_features': max_features, 'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf,'bootstrap': bootstrap}\n",
        "\n",
        "# 테스트 데이터\n",
        "X_finaltest = test_df[0].values\n",
        "y_finaltest = test_df[1].values\n",
        "\n",
        "kfold_outter = KFold(n_splits=NUM_FOLDS_OUTTER, shuffle=True, random_state=42)\n",
        "\n",
        "d = {'k': [], 'Accuracy': [], 'Precision': [], 'Recall': [],'AUC ROC': [], 'auc pr': []}\n",
        "df_marks = pd.DataFrame(d)\n",
        "\n",
        "features = train_df[0].values\n",
        "target = train_df[1].values\n",
        "n_class = train_df[2]\n",
        "print(\"n_class :\")\n",
        "print(n_class)\n",
        "multiclass = n_class > 2\n",
        "\n",
        "k = 2\n",
        "UP = 12\n",
        "SIZE = 36\n",
        "\n",
        "best_model = None\n",
        "highest_auc = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델 불러와서 학습"
      ],
      "metadata": {
        "id": "DWy4XEz-eFzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 학습_gan6\n",
        "for index, (train, test) in enumerate(kfold_outter.split(features, target)):\n",
        "    image_convertor = Tab2Img()\n",
        "\n",
        "    X_train = features[train]\n",
        "    y_train = target[train]\n",
        "    X_test = features[test]\n",
        "    y_test = target[test]\n",
        "\n",
        "    ## image 변환\n",
        "    x_train_images = image_convertor.fit_transform(X_train, y_train)\n",
        "    x_test_images = image_convertor.transform(X_test)\n",
        "\n",
        "    x_train_images = (np.repeat(x_train_images[..., np.newaxis], 3, -1))\n",
        "    x_train_images = tf.image.resize(x_train_images, (SIZE, SIZE))\n",
        "    x_test_images = (np.repeat(x_test_images[..., np.newaxis], 3, -1))\n",
        "    x_test_images = tf.image.resize(x_test_images, (SIZE, SIZE))\n",
        "\n",
        "    Y_train_onehot = one_hot(y_train, n_class)\n",
        "    Y_test_onehot = one_hot(y_test, n_class)\n",
        "\n",
        "    ## teacher model\n",
        "    teacher = convolutional_neural_network(UP, UP, SIZE, SIZE, num_classes=n_class)\n",
        "    print(\"====x_train_images.shape====\")\n",
        "    print(x_train_images.shape)\n",
        "    print(\"====Y_train_onehot.shape====\")\n",
        "    print(Y_train_onehot.shape)\n",
        "\n",
        "    clallback = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",min_delta=0,patience=28,verbose=0,mode=\"auto\",baseline=None,restore_best_weights=True,\n",
        "    )\n",
        "    start = time.time()\n",
        "\n",
        "    print(\"====Now teacher model fitting====\")\n",
        "    teacher.fit(x_train_images, Y_train_onehot, batch_size=16, validation_split=0.1, epochs=20, verbose=1)\n",
        "    teacher.save(\"/content/teacher_model.h5\")\n",
        "\n",
        "    ## best model 추출\n",
        "    best_model = load_model('/content/best_model_ganTLTD(0.76).h5')\n",
        "    extract = Model(inputs=best_model.inputs, outputs=best_model.layers[-2].output)\n",
        "\n",
        "    features_train = extract.predict(features)\n",
        "    features_test = extract.predict(X_finaltest)\n",
        "\n",
        "    X_train_concatenate = np.concatenate([features, features_train], axis=-1)\n",
        "    X_test_concatenate = np.concatenate([X_finaltest, features_test], axis=-1)\n",
        "\n",
        "    ## RF Classifier\n",
        "    clf = RandomForestClassifier()\n",
        "    clf = RandomizedSearchCV(estimator=clf, param_distributions=random_grid, cv=3, verbose=0,random_state=42)\n",
        "    print(\"====Now RF model fitting====\")\n",
        "    clf = clf.fit(X_train_concatenate, target)\n",
        "    end = time.time()\n",
        "    print(end - start)\n",
        "\n",
        "    Y_proba = clf.predict_proba(X_test_concatenate)\n",
        "    Y_pred = clf.predict(X_test_concatenate)\n",
        "    dump(clf, \"/content/rf_model.joblib\")\n",
        "\n",
        "    acc, precision, recall, auc_pr, auc_roc = \\\n",
        "        eval_metrics(y_finaltest, Y_pred, Y_proba, multiclass=True, n_class=n_class)\n",
        "    best_params = clf.best_params_\n",
        "\n",
        "    new_row = {\n",
        "    'k': k, 'Accuracy': acc, 'Precision': precision, 'Recall': recall,\n",
        "    'AUC ROC': auc_roc, 'auc pr': auc_pr,\n",
        "    'Best n_estimators': best_params['n_estimators'],\n",
        "    'Best max_features': best_params['max_features'], 'Best max_depth': best_params['max_depth'],\n",
        "    'Best min_samples_split': best_params['min_samples_split'], 'Best min_samples_leaf': best_params['min_samples_leaf'],\n",
        "    'Best bootstrap': best_params['bootstrap']\n",
        "}\n",
        "    print(new_row)\n",
        "    df_marks = pd.concat([df_marks, pd.DataFrame([new_row])], ignore_index=True)\n",
        "\n",
        "    # classification report 생성\n",
        "    report = classification_report(y_finaltest, Y_pred, output_dict=True)\n",
        "    df_report = pd.DataFrame(report).transpose()\n",
        "    df_report_class_only = df_report.iloc[:-3, :][['precision', 'recall', 'f1-score']]\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    colors = sns.color_palette(\"Blues\", n_colors=len(df_report_class_only.columns))\n",
        "    df_report_class_only.plot(kind='bar', ax=ax, color=colors)\n",
        "    ax.set_title(\"Classification Report\")\n",
        "    ax.set_xlabel(\"Classes\")\n",
        "    ax.set_ylabel(\"Scores\")\n",
        "    plt.xticks(ticks=range(len(np.unique(y_finaltest))), labels=np.unique(y_finaltest), rotation=45)\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bbahvrUsunnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 처음부터 학습"
      ],
      "metadata": {
        "id": "mwkyP7R3e3Pk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63LNRaDrflB9"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from joblib import dump, load\n",
        "\n",
        "for index, (train, test) in enumerate(kfold_outter.split(features, target)):\n",
        "    image_convertor = Tab2Img()\n",
        "\n",
        "    X_train = features[train]\n",
        "    y_train = target[train]\n",
        "    X_test = features[test]\n",
        "    y_test = target[test]\n",
        "\n",
        "    ## image 변환\n",
        "    x_train_images = image_convertor.fit_transform(X_train, y_train)\n",
        "    x_test_images = image_convertor.transform(X_test)\n",
        "\n",
        "    x_train_images = (np.repeat(x_train_images[..., np.newaxis], 3, -1))\n",
        "    x_train_images = tf.image.resize(x_train_images, (SIZE, SIZE))\n",
        "    x_test_images = (np.repeat(x_test_images[..., np.newaxis], 3, -1))\n",
        "    x_test_images = tf.image.resize(x_test_images, (SIZE, SIZE))\n",
        "\n",
        "    Y_train_onehot = one_hot(y_train, n_class)\n",
        "    Y_test_onehot = one_hot(y_test, n_class)\n",
        "\n",
        "    ## teacher model\n",
        "    teacher = convolutional_neural_network(UP, UP, SIZE, SIZE, num_classes=n_class)\n",
        "    print(\"====x_train_images.shape====\")\n",
        "    print(x_train_images.shape)\n",
        "    print(\"====Y_train_onehot.shape====\")\n",
        "    print(Y_train_onehot.shape)\n",
        "\n",
        "    clallback = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",min_delta=0,patience=28,verbose=0,mode=\"auto\",baseline=None,restore_best_weights=True,\n",
        "    )\n",
        "    start = time.time()\n",
        "\n",
        "    print(\"====Now teacher model fitting====\")\n",
        "    teacher.fit(x_train_images, Y_train_onehot, batch_size=16, validation_split=0.1, epochs=20, verbose=1)\n",
        "    teacher.save(\"/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/gan2_teacher_model2.h5\")\n",
        "\n",
        "    ## student model\n",
        "    for i in range(5):\n",
        "        student = fcnn_lib.fully_fcnn(n_class=n_class)\n",
        "        distiller = Distiller.Distiller(student=student, teacher=teacher)\n",
        "        distiller.compile(\n",
        "            optimizer='adam',metrics=['accuracy'],\n",
        "            student_loss_fn=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "            distillation_loss_fn=keras.losses.KLDivergence(),alpha=0.1,temperature=15,\n",
        "        )\n",
        "\n",
        "        print(\"====Now student model fitting====\")\n",
        "        distiller.fit([x_train_images, X_train], Y_train_onehot, verbose=2, epochs=50, batch_size=16)\n",
        "\n",
        "        Y_proba = distiller.predict(X_test)\n",
        "        Y_pred = Y_proba.argmax(axis=1)\n",
        "\n",
        "        acc, precision, recall, auc_pr, auc_roc = \\\n",
        "            eval_metrics(y_test, Y_pred, Y_proba, multiclass=multiclass, n_class=n_class)\n",
        "\n",
        "        if auc_roc > highest_auc:\n",
        "            highest_auc = auc_roc\n",
        "            best_model = distiller\n",
        "\n",
        "    ## best model 추출\n",
        "    extract = Model(inputs=best_model.student.inputs, outputs=best_model.student.layers[-2].output)\n",
        "    extract.save(\"/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/gan2_student_model2.h5\")\n",
        "\n",
        "    features_train = extract.predict(features)\n",
        "    features_test = extract.predict(X_finaltest)\n",
        "\n",
        "    X_train_concatenate = np.concatenate([features, features_train], axis=-1)\n",
        "    X_test_concatenate = np.concatenate([X_finaltest, features_test], axis=-1)\n",
        "\n",
        "    ## RF Classifier\n",
        "    clf = RandomForestClassifier()\n",
        "    clf = RandomizedSearchCV(estimator=clf, param_distributions=random_grid, cv=3, verbose=0,random_state=42)\n",
        "    print(\"====Now RF model fitting====\")\n",
        "    clf = clf.fit(X_train_concatenate, target)\n",
        "    end = time.time()\n",
        "    print(end - start)\n",
        "\n",
        "    Y_proba = clf.predict_proba(X_test_concatenate)\n",
        "    Y_pred = clf.predict(X_test_concatenate)\n",
        "    dump(clf, \"/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/gan2_rf_model2.joblib\")\n",
        "\n",
        "    acc, precision, recall, auc_pr, auc_roc = \\\n",
        "        eval_metrics(y_finaltest, Y_pred, Y_proba, multiclass=True, n_class=n_class)\n",
        "    best_params = clf.best_params_\n",
        "\n",
        "    new_row = {\n",
        "    'k': k, 'Accuracy': acc, 'Precision': precision, 'Recall': recall,\n",
        "    'AUC ROC': auc_roc, 'auc pr': auc_pr,\n",
        "    'Best n_estimators': best_params['n_estimators'],\n",
        "    'Best max_features': best_params['max_features'], 'Best max_depth': best_params['max_depth'],\n",
        "    'Best min_samples_split': best_params['min_samples_split'], 'Best min_samples_leaf': best_params['min_samples_leaf'],\n",
        "    'Best bootstrap': best_params['bootstrap']\n",
        "}\n",
        "    print(new_row)\n",
        "    df_marks = pd.concat([df_marks, pd.DataFrame([new_row])], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from joblib import load\n",
        "\n",
        "# 모델 경로와 모델 이름\n",
        "model_paths = [\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/gan2_rf_model2.joblib\",\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/gan4_rf_model.joblib\",\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/gan6_rf_model.joblib\",\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/ctgan_rf_model.joblib\",\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/cgan_rf_model.joblib\",\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/origin_rf_model2.joblib\"\n",
        "]\n",
        "model_names = [\"GAN2\", \"GAN4\", \"GAN6\", \"CTGAN\", \"CGAN\", \"Original\"]\n",
        "\n",
        "# 그래프 초기화\n",
        "plt.figure(figsize=(10, 8))\n",
        "colors = ['blue', 'green', 'red', 'purple', 'orange', 'cyan']\n",
        "\n",
        "# 각 모델에 대해 ROC 곡선 그리기\n",
        "for i, model_path in enumerate(model_paths):\n",
        "    # 모델 불러오기\n",
        "    clf = load(model_path)\n",
        "\n",
        "    # 예측 확률 계산\n",
        "    Y_proba = clf.predict_proba(X_test_concatenate)  # X_test_concatenate는 테스트 데이터\n",
        "    fpr, tpr, _ = roc_curve(y_finaltest, Y_proba[:, 1], pos_label=1)  # 이진 분류인 경우 pos_label 설정\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # ROC 곡선 추가\n",
        "    plt.plot(fpr, tpr, color=colors[i], lw=2, label=f'{model_names[i]} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "# 그래프 설정\n",
        "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison for Multiple Models')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-ChP_bG4sj7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 최종 시각화 코드"
      ],
      "metadata": {
        "id": "w14myvOswEsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "M59ArjfRwIiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "original"
      ],
      "metadata": {
        "id": "RthGIm95wpyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, accuracy_score, recall_score, precision_recall_curve, auc\n",
        "from sklearn import metrics\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from tab2img.converter import Tab2Img\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Reshape, GlobalAveragePooling2D, MaxPool2D, UpSampling2D,Lambda\n",
        "from tensorflow.keras import applications as efn\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from joblib import dump, load"
      ],
      "metadata": {
        "id": "014DmBoS3w6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 5  # You can change this to the desired number of splits\n",
        "\n",
        "# Initialize KFold (or any other splitter you wish)\n",
        "kfold_outter = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# ROC AUC 값을 저장할 DataFrame 생성\n",
        "origin_roc_auc_df = pd.DataFrame(columns=['k', 'Class', 'AUC'])\n",
        "\n",
        "## 학습_gan6\n",
        "for index, (train, test) in enumerate(kfold_outter.split(features, target)):\n",
        "    image_convertor = Tab2Img()\n",
        "\n",
        "    X_train = features[train]\n",
        "    y_train = target[train]\n",
        "    X_test = features[test]\n",
        "    y_test = target[test]\n",
        "\n",
        "    ## image 변환\n",
        "    x_train_images = image_convertor.fit_transform(X_train, y_train)\n",
        "    x_test_images = image_convertor.transform(X_test)\n",
        "\n",
        "    x_train_images = (np.repeat(x_train_images[..., np.newaxis], 3, -1))\n",
        "    x_train_images = tf.image.resize(x_train_images, (SIZE, SIZE))\n",
        "    x_test_images = (np.repeat(x_test_images[..., np.newaxis], 3, -1))\n",
        "    x_test_images = tf.image.resize(x_test_images, (SIZE, SIZE))\n",
        "\n",
        "    Y_train_onehot = one_hot(y_train, n_class)\n",
        "    Y_test_onehot = one_hot(y_test, n_class)\n",
        "\n",
        "    ## teacher model\n",
        "    teacher = convolutional_neural_network(UP, UP, SIZE, SIZE, num_classes=n_class)\n",
        "    print(\"====x_train_images.shape====\")\n",
        "    print(x_train_images.shape)\n",
        "    print(\"====Y_train_onehot.shape====\")\n",
        "    print(Y_train_onehot.shape)\n",
        "\n",
        "    clallback = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", min_delta=0, patience=28, verbose=0, mode=\"auto\", baseline=None, restore_best_weights=True,\n",
        "    )\n",
        "    start = time.time()\n",
        "\n",
        "    print(\"====Now teacher model fitting====\")\n",
        "    teacher.fit(x_train_images, Y_train_onehot, batch_size=16, validation_split=0.1, epochs=20, verbose=1)\n",
        "\n",
        "    ## best model 추출\n",
        "    best_model = load_model(\"/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/origin_teacher_model2.joblib\")\n",
        "    extract = Model(inputs=best_model.inputs, outputs=best_model.layers[-2].output)\n",
        "\n",
        "    features_train = extract.predict(features)\n",
        "    features_test = extract.predict(X_finaltest)\n",
        "\n",
        "    X_train_concatenate = np.concatenate([features, features_train], axis=-1)\n",
        "    X_test_concatenate = np.concatenate([X_finaltest, features_test], axis=-1)\n",
        "\n",
        "    ## RF Classifier\n",
        "    clf = RandomForestClassifier()\n",
        "    clf = RandomizedSearchCV(estimator=clf, param_distributions=random_grid, cv=3, verbose=0, random_state=42)\n",
        "    print(\"====Now RF model fitting====\")\n",
        "    clf = clf.fit(X_train_concatenate, target)\n",
        "    end = time.time()\n",
        "    print(end - start)\n",
        "\n",
        "    Y_proba = clf.predict_proba(X_test_concatenate)\n",
        "    Y_pred = clf.predict(X_test_concatenate)\n",
        "\n",
        "    acc, precision, recall, auc_pr, auc_roc = \\\n",
        "        eval_metrics(y_finaltest, Y_pred, Y_proba, multiclass=True, n_class=n_class)\n",
        "    best_params = clf.best_params_\n",
        "\n",
        "    new_row = {\n",
        "        'k': k, 'Accuracy': acc, 'Precision': precision, 'Recall': recall,\n",
        "        'AUC ROC': auc_roc, 'auc pr': auc_pr,\n",
        "        'Best n_estimators': best_params['n_estimators'],\n",
        "        'Best max_features': best_params['max_features'], 'Best max_depth': best_params['max_depth'],\n",
        "        'Best min_samples_split': best_params['min_samples_split'], 'Best min_samples_leaf': best_params['min_samples_leaf'],\n",
        "        'Best bootstrap': best_params['bootstrap']\n",
        "    }\n",
        "    print(new_row)\n",
        "    df_marks = pd.concat([df_marks, pd.DataFrame([new_row])], ignore_index=True)\n",
        "\n",
        "    ## ROC Curve 및 AUC 저장\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    for i in range(n_class):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_finaltest == i, Y_proba[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "        # AUC 값을 roc_auc_df에 저장\n",
        "        new_auc_row = {\n",
        "            'k': k,\n",
        "            'Class': i,\n",
        "            'AUC': roc_auc[i]\n",
        "        }\n",
        "        origin_roc_auc_df = pd.concat([origin_roc_auc_df, pd.DataFrame([new_auc_row])], ignore_index=True)\n",
        "\n",
        "    # ROC curve 그리기\n",
        "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_class)]))\n",
        "    mean_tpr = np.zeros_like(all_fpr)\n",
        "    for i in range(n_class):\n",
        "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "    mean_tpr /= n_class\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(all_fpr, mean_tpr, color='darkorange', lw=2, label='ROC')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
        "    plt.xlabel('1-Specificity')\n",
        "    plt.ylabel('Sensitivity')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Average ROC curve')\n",
        "    plt.show()\n",
        "\n",
        "    ## classification report 생성\n",
        "    report = classification_report(y_finaltest, Y_pred, output_dict=True)\n",
        "    df_report = pd.DataFrame(report).transpose()\n",
        "\n",
        "    # 클래스별 Precision, Recall, F1-Score 추출\n",
        "    df_report_class_only = df_report.iloc[:-3, :][['precision', 'recall', 'f1-score']]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    colors = sns.color_palette(\"Blues\", n_colors=len(df_report_class_only.columns))\n",
        "\n",
        "    # Plotting with custom colors\n",
        "    df_report_class_only.plot(kind='bar', ax=ax, color=colors)\n",
        "\n",
        "    # Setting chart labels\n",
        "    ax.set_title(\"Classification Report\")\n",
        "    ax.set_xlabel(\"Classes\")\n",
        "    ax.set_ylabel(\"Scores\")\n",
        "    plt.xticks(ticks=range(len(np.unique(y_finaltest))), labels=np.unique(y_finaltest), rotation=45)\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Display chart\n",
        "    plt.show()\n",
        "\n",
        "# roc_auc_df 출력\n",
        "print(origin_roc_auc_df)\n"
      ],
      "metadata": {
        "id": "0Lseg7wxwHzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Urep/gan_data/gan_train_15k.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Urep/gan_data/gan_test_15k.csv')"
      ],
      "metadata": {
        "id": "b8zwvF12ym2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.drop(columns=['y'])  # 'label' 컬럼을 제외한 특성\n",
        "y_train = train['y']  # 'label' 컬럼을 레이블로 설정\n",
        "X_test = test.drop(columns=['y'])\n",
        "y_test = test['y']"
      ],
      "metadata": {
        "id": "XrBV9ZrPy4TD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_class = len(np.unique(y_test))"
      ],
      "metadata": {
        "id": "jPcOhwhnzkVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = joblib.load('/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/origin_rf_model2.joblib')"
      ],
      "metadata": {
        "id": "4OC4togJ0Kct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "aev6qFGg5Txo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# 데이터 불러오기\n",
        "train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Urep/gan_data/gan_train_15k.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Urep/gan_data/gan_test_15k.csv')\n",
        "\n",
        "# features와 target 정의 (train, test 데이터셋에 맞게 수정)\n",
        "X_train = train.drop(columns='y')  # target을 제외한 피처들\n",
        "y_train = train['y']  # target 컬럼\n",
        "\n",
        "X_test = test.drop(columns='y')  # test 데이터셋에서 target을 제외한 피처들\n",
        "y_test = test['y']  # test 데이터셋의 target\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# image 변환기 정의\n",
        "image_convertor = Tab2Img()\n",
        "\n",
        "# X_train과 X_test를 이미지로 변환\n",
        "x_train_images = image_convertor.fit_transform(X_train, y_train_encoded)\n",
        "x_test_images = image_convertor.transform(X_test)\n",
        "\n",
        "# 이미지의 차원 맞추기 (RGB 채널 3개로 확장)\n",
        "x_train_images = np.repeat(x_train_images[..., np.newaxis], 3, -1)\n",
        "x_train_images = tf.image.resize(x_train_images, (SIZE, SIZE))  # SIZE는 사전 정의된 크기\n",
        "x_test_images = np.repeat(x_test_images[..., np.newaxis], 3, -1)\n",
        "x_test_images = tf.image.resize(x_test_images, (SIZE, SIZE))\n",
        "\n",
        "# one-hot encoding\n",
        "Y_train_onehot = one_hot(y_train, n_class)\n",
        "Y_test_onehot = one_hot(y_test, n_class)\n",
        "\n",
        "# teacher 모델 정의 및 학습\n",
        "teacher = convolutional_neural_network(UP, UP, SIZE, SIZE, num_classes=n_class)\n",
        "teacher.fit(x_train_images, Y_train_onehot, batch_size=16, validation_split=0.1, epochs=20, verbose=1)\n",
        "\n",
        "# best 모델 추출\n",
        "best_model = load_model(\"/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/origin_teacher_model2.joblib\")\n",
        "extract = Model(inputs=best_model.inputs, outputs=best_model.layers[-2].output)\n",
        "\n",
        "# teacher 모델을 통해 특성 추출\n",
        "features_train = extract.predict(x_train_images)\n",
        "features_test = extract.predict(x_test_images)\n",
        "\n",
        "# 원본 특성과 teacher 모델 특성 결합\n",
        "X_train_concatenate = np.concatenate([X_train, features_train], axis=-1)\n",
        "X_test_concatenate = np.concatenate([X_test, features_test], axis=-1)\n",
        "\n",
        "# 이미 학습된 Random Forest 모델 불러오기\n",
        "rf_model = joblib.load('/content/drive/MyDrive/Colab Notebooks/Urep/origin_rf_model2.joblib')  # 모델 경로\n",
        "\n",
        "# 예측 및 성능 평가\n",
        "Y_proba = rf_model.predict_proba(X_test_concatenate)\n",
        "Y_pred = rf_model.predict(X_test_concatenate)\n",
        "\n",
        "# AUC 계산\n",
        "acc, precision, recall, auc_pr, auc_roc = eval_metrics(y_test, Y_pred, Y_proba, multiclass=True, n_class=n_class)\n",
        "\n",
        "# ROC AUC 저장\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_class):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test == i, Y_proba[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    new_auc_row = {'Class': i, 'AUC': roc_auc[i]}\n",
        "    origin_roc_auc_df = pd.concat([origin_roc_auc_df, pd.DataFrame([new_auc_row])], ignore_index=True)\n",
        "\n",
        "# ROC curve 그리기\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_class)]))\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_class):\n",
        "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "mean_tpr /= n_class\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(all_fpr, mean_tpr, color='darkorange', lw=2, label='ROC')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
        "plt.xlabel('1-Specificity')\n",
        "plt.ylabel('Sensitivity')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Average ROC curve')\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "report = classification_report(y_test, Y_pred, output_dict=True)\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "\n",
        "# 클래스별 Precision, Recall, F1-Score 출력\n",
        "df_report_class_only = df_report.iloc[:-3, :][['precision', 'recall', 'f1-score']]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "colors = sns.color_palette(\"Blues\", n_colors=len(df_report_class_only.columns))\n",
        "df_report_class_only.plot(kind='bar', ax=ax, color=colors)\n",
        "\n",
        "ax.set_title(\"Classification Report\")\n",
        "ax.set_xlabel(\"Classes\")\n",
        "ax.set_ylabel(\"Scores\")\n",
        "plt.xticks(ticks=range(len(np.unique(y_test))), labels=np.unique(y_test), rotation=45)\n",
        "plt.legend(loc='lower right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# AUC 결과 출력\n",
        "print(origin_roc_auc_df)\n"
      ],
      "metadata": {
        "id": "C6DjUwZMyHya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Student 모델 경로 리스트\n",
        "student_model_paths = [\n",
        "    '/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/origin_student_model2.h5',\n",
        "    '/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/gan2_student_model2.h5',\n",
        "    '/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/gan4_student_model.h5',\n",
        "    '/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/Copy of student_model_gan7730.h5',\n",
        "    '/content/drive/MyDrive/Colab Notebooks/Urep/최종모델파일/student_model_ctgan5507.h5',\n",
        "    '/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/Copy of student_model_cgan5871.h5'\n",
        "]\n",
        "\n",
        "# RF 모델 경로 리스트\n",
        "rf_model_paths = [\n",
        "    '/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/origin_rf_model2.joblib',\n",
        "    '/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/gan2_rf_model2.joblib',\n",
        "    '/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/gan4_rf_model.joblib',\n",
        "    '/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/gan6_rf_model.joblib',\n",
        "    '/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/ctgan_rf_model.joblib',\n",
        "    '/content/drive/MyDrive/Colab Notebooks/Urep/TLTD_model/cgan_rf_model.joblib'\n",
        "]\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from tensorflow.keras.models import load_model\n",
        "from joblib import load\n",
        "\n",
        "# 모델에 해당하는 레전드 이름과 색상 리스트\n",
        "model_names = ['Original Dataset', 'GAN 2x Dataset', 'GAN 4x Dataset', 'GAN 6x Dataset(Best)', 'CTGAN 6x Dataset', 'CGAN 6x Dataset']\n",
        "colors = ['b', 'g', 'r', 'c', 'm', 'y']  # 각 모델에 대한 색상 리스트\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "# 각 모델에 대해 반복하여 ROC 곡선을 계산하고 그리기\n",
        "for i in range(6):  # 6개의 모델에 대해\n",
        "    # Student 모델 로드\n",
        "    student_model = load_model(student_model_paths[i])\n",
        "    rf_model = load(rf_model_paths[i])\n",
        "\n",
        "    # Student 모델 특징 추출\n",
        "    student_features_test = student_model.predict(X_finaltest)\n",
        "    X_test_student = np.concatenate([X_finaltest, student_features_test], axis=-1)\n",
        "\n",
        "    # RF 모델 예측\n",
        "    student_rf_probs = rf_model.predict_proba(X_test_student)\n",
        "\n",
        "    # ROC Curve 계산\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "\n",
        "    # 각 클래스별로 ROC curve 계산\n",
        "    for j in range(n_class):\n",
        "        fpr[j], tpr[j], _ = roc_curve(y_finaltest == j, student_rf_probs[:, j])\n",
        "        roc_auc[j] = auc(fpr[j], tpr[j])\n",
        "\n",
        "    # Macro-average ROC curve\n",
        "    all_fpr = np.unique(np.concatenate([fpr[j] for j in range(n_class)]))\n",
        "    mean_tpr = np.zeros_like(all_fpr)\n",
        "\n",
        "    # 평균 TPR 계산\n",
        "    for j in range(n_class):\n",
        "        mean_tpr += np.interp(all_fpr, fpr[j], tpr[j])\n",
        "    mean_tpr /= n_class\n",
        "\n",
        "    # Macro-average ROC curve 그리기\n",
        "    macro_roc_auc = auc(all_fpr, mean_tpr)\n",
        "    plt.plot(all_fpr, mean_tpr, color=colors[i], lw=2, label=f'{model_names[i]}')\n",
        "    plt.plot(all_fpr, mean_tpr, color=colors[i], lw=2, label=f'{model_names[i]} (AUC = {macro_roc_auc:.4f})')\n",
        "\n",
        "# 대각선 기준선 그리기 (무작위 예측)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "\n",
        "# 레이블 설정\n",
        "plt.xlabel('1-Specificity')\n",
        "plt.ylabel('Sensitivity')\n",
        "plt.title('ROC Curve Comparison for Each Model')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# 그래프 출력\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IH3hSM7QPUea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# 모델별 classification report 저장용 리스트\n",
        "classification_reports = []\n",
        "\n",
        "# 각 모델에 대해 반복하여 classification report 생성 및 저장\n",
        "for i in range(6):\n",
        "    # Student 모델 로드\n",
        "    student_model = load_model(student_model_paths[i])\n",
        "    rf_model = load(rf_model_paths[i])\n",
        "\n",
        "    # Student 모델 특징 추출\n",
        "    student_features_test = student_model.predict(X_finaltest)\n",
        "    X_test_student = np.concatenate([X_finaltest, student_features_test], axis=-1)\n",
        "\n",
        "    # RF 모델 예측\n",
        "    y_pred = rf_model.predict(X_test_student)\n",
        "\n",
        "    # classification report 생성 및 데이터프레임으로 변환\n",
        "    report = classification_report(y_finaltest, y_pred, output_dict=True)\n",
        "    report_df = pd.DataFrame(report).transpose()\n",
        "    report_df['model'] = model_names[i]  # 모델 이름 추가\n",
        "    classification_reports.append(report_df)\n",
        "\n",
        "# 모든 모델의 classification report를 하나의 데이터프레임으로 합치기\n",
        "combined_report_df = pd.concat(classification_reports)\n",
        "\n",
        "# 모델 별로 그래프를 그리기 위해 모델과 클래스 정보를 index로 설정\n",
        "combined_report_df.reset_index(inplace=True)\n",
        "combined_report_df = combined_report_df.rename(columns={'index': 'class'})\n",
        "\n",
        "# Precision, Recall, F1-score 막대 그래프 그리기\n",
        "metrics = ['precision', 'recall', 'f1-score']\n",
        "plt.figure(figsize=(15, 8))\n",
        "for metric in metrics:\n",
        "    sns.barplot(x='class', y=metric, hue='model', data=combined_report_df[combined_report_df['class'].isin(['0', '1', '2'])])\n",
        "    plt.title(f'{metric.capitalize()} Comparison for Each Model')\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel(metric.capitalize())\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "SzYeu-fWSsoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# GAN 4 모델 로드\n",
        "student_model = load_model(student_model_paths[2])  # GAN 4 모델 경로\n",
        "rf_model = load(rf_model_paths[2])\n",
        "\n",
        "# Student 모델 특징 추출\n",
        "student_features_test = student_model.predict(X_finaltest)\n",
        "X_test_student = np.concatenate([X_finaltest, student_features_test], axis=-1)\n",
        "\n",
        "# RF 모델 예측\n",
        "y_pred = rf_model.predict(X_test_student)\n",
        "\n",
        "# classification report 생성 및 데이터프레임으로 변환\n",
        "report = classification_report(y_finaltest, y_pred, output_dict=True)\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Precision, Recall, F1-score 막대 그래프 그리기\n",
        "metrics = ['precision', 'recall', 'f1-score']\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# 각 성능 지표별로 그래프 생성\n",
        "for metric in metrics:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x=report_df.index[:-3], y=report_df[metric][:-3], palette='viridis')\n",
        "    plt.title(f'GAN 4 Model {metric.capitalize()} for Each Class')\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel(metric.capitalize())\n",
        "    plt.ylim(0, 1)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "q4s7bDEETlvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GAN 4 모델 로드\n",
        "student_model = load_model(student_model_paths[2])  # GAN 4 모델 경로\n",
        "rf_model = load(rf_model_paths[2])\n",
        "\n",
        "# Student 모델 특징 추출\n",
        "student_features_test = student_model.predict(X_finaltest)\n",
        "X_test_student = np.concatenate([X_finaltest, student_features_test], axis=-1)\n",
        "\n",
        "# RF 모델 예측\n",
        "y_pred = rf_model.predict(X_test_student)\n",
        "\n",
        "# classification report 생성 및 데이터프레임으로 변환\n",
        "report = classification_report(y_finaltest, y_pred, output_dict=True)\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "\n",
        "# 클래스별 Precision, Recall, F1-Score 추출\n",
        "df_report_class_only = df_report.iloc[:-3, :][['precision', 'recall', 'f1-score']]\n",
        "\n",
        "# 그래프 그리기\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "colors = sns.color_palette(\"Blues\", n_colors=len(df_report_class_only.columns))\n",
        "\n",
        "# Plotting with custom colors\n",
        "df_report_class_only.plot(kind='bar', ax=ax, color=colors)\n",
        "\n",
        "# Setting chart labels\n",
        "ax.set_title(\"GAN 4x Model Classification Report\")\n",
        "ax.set_xlabel(\"Classes\")\n",
        "ax.set_ylabel(\"Scores\")\n",
        "plt.xticks(ticks=range(len(np.unique(y_finaltest))), labels=np.unique(y_finaltest), rotation=45)\n",
        "plt.legend(loc='lower right')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display chart\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VWXjCQEFT5C3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}